{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prot10/ADM_HW_3/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlJEob8B5Zt8"
      },
      "source": [
        "# __Homework 3 - Places of the world__\n",
        "\n",
        "Travelling is a pleasant activity which has increased since the end of the COVID-19 pandemic. Nowadays, people look for places to visit which are attractive, affordable, with a rich history and which have recommended activities. Using user-generated content, [Atlas Obscura](https://www.atlasobscura.com), an American online magazine and travel firm, catalogues unusual and obscure tourist locations. The website's articles span many subjects, including history, science, cuisine, and unique places.\n",
        "\n",
        "You and your team have been hired to provide your Data Science knowledge to create a search engine which will facilitate specific searches towards a topic related to the most popular places to visit. Important: All the functions must be implemented from scratch unless differently specified.\n",
        "\n",
        "Then, let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwMmIjF2NfVr",
        "outputId": "3e3377e4-792d-4c0e-82d3-8badb2ed0a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting geocoder\n",
            "  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from geocoder) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from geocoder) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from geocoder) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from geocoder) (7.1.2)\n",
            "Collecting ratelim\n",
            "  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ratelim->geocoder) (4.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (2.10)\n",
            "Installing collected packages: ratelim, geocoder\n",
            "Successfully installed geocoder-1.38.1 ratelim-0.1.6\n"
          ]
        }
      ],
      "source": [
        "pip install geocoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQctLMnENffQ",
        "outputId": "a8744981-9f25-40fa-dbfb-eb50fcee1e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting haversine\n",
            "  Downloading haversine-2.7.0-py2.py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: haversine\n",
            "Successfully installed haversine-2.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install haversine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfVP4O4c5jyV",
        "outputId": "e8c74586-73a3-4c4b-e9fb-159d1e7bb2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import lxml\n",
        "import requests\n",
        "import urllib.request \n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import codecs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "import pickle\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import geocoder\n",
        "import haversine as hs\n",
        "import heapq\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS1yLBWVC0S4",
        "outputId": "35ecc3fd-c705-431f-83fb-aebcd5404aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q6ow4js5oHd"
      },
      "source": [
        "## 1. Data collection\n",
        "\n",
        "For this homework, there is no provided dataset. Instead, you have to build your own. Your search engine will run on text documents. So, here we detail the procedure to follow for the data collection.\n",
        "\n",
        "### 1.1. Get the list of places\n",
        "We start with the list of places to include in your corpus of documents. In particular, we focus on the [Most popular places](https://www.atlasobscura.com/places?sort=likes_count). Next, we want you to __collect the URL__ associated with each site in the list from this list. The list is long and split into many pages. Therefore, we ask you to retrieve only the URLs of the places listed in the __first 400 pages__ (each page has 18 places, so that you will end up with 7200 unique place URLs).\n",
        "\n",
        "The output of this step is a `.txt` file whose single line corresponds to the place's URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF95pure5nmH"
      },
      "outputs": [],
      "source": [
        "# create a text file\n",
        "LinkFiles = open(\"/content/drive/MyDrive/ADM_HW_3/places_lists.txt\", \"w\")\n",
        "# save the URL assiociated to the places in the first 400 pages\n",
        "for i in tqdm(range(1, 401)):\n",
        "    url = 'https://www.atlasobscura.com/places?page=' +str(i)+'&sort=likes_count' \n",
        "\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, features='lxml')\n",
        "    for a in soup.find_all('a', class_=\"content-card content-card-place\"):\n",
        "        LinkFiles.write(a.get('href')+'\\n')\n",
        "\n",
        "LinkFiles.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae5Iwc8K5u5P"
      },
      "source": [
        "### 1.2. Crawl places\n",
        "\n",
        "Once you get all the URLs in the first 400 pages of the list, you:\n",
        "\n",
        "1. Download the `HTML` corresponding to each of the collected URLs.\n",
        "\n",
        "2. After you collect a single page, immediately save its `HTML` in a file. In this way, if your program stops for any reason, you will not lose the data collected up to the stopping point.\n",
        "\n",
        "3. Organize the entire set of downloaded `HTML` pages into folders. Each folder will contain the `HTML` of the places on page 1, page 2, ... of the list of locations.\n",
        "\n",
        "__Tip:__ Due to a large number of pages you should download, you can use some methods that can help you shorten the time it takes. If you employed a particular process or approach, kindly describe it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLovGUSR5wDY"
      },
      "outputs": [],
      "source": [
        "#creating a subfolder to store the html file of the page 'page'\n",
        "for page in tqdm(range(1,401)):\n",
        "    subfolder = \"/content/drive/MyDrive/ADM_HW_3/html_page/page_{}\".format(page)\n",
        "    os.makedirs(subfolder)\n",
        "\n",
        "    f = open(\"/content/drive/MyDrive/ADM_HW_3/places_lists.txt\", 'r', encoding=\"utf8\")\n",
        "    lines = f.readlines()[(page-1)*18:(page)*18]\n",
        "    lines = [line.rstrip() for line in lines]\n",
        "    f.close\n",
        "\n",
        "    i = 1+18*(page-1)\n",
        "    #for each link that we read let's create a new .html file\n",
        "    for link in lines:\n",
        "        link = ' https://www.atlasobscura.com' + link\n",
        "        html = requests.get(link)\n",
        "    \n",
        "        \n",
        "        file_name = '{}/{}.html'.format(subfolder, i)\n",
        "        g = open(file_name, 'w', encoding=\"utf8\")\n",
        "        g.write(html.text)\n",
        "        g.close\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5O1GURD5wp6"
      },
      "source": [
        "### 1.3 Parse downloaded pages\n",
        "\n",
        "At this point, you should have all the HTML documents about the places of interest, and you can start to extract the places' information. The list of the information we desire for each place and their format is as follows:\n",
        "\n",
        "1. Place Name (to save as `placeName`): String.\n",
        "2. Place Tags (to save as `placeTags`): List of Strings.\n",
        "3. \\# of people who have been there (to save as `numPeopleVisited`): Integer.\n",
        "4. \\# of people who want to visit the place(to save as `numPeopleWant`): Integer.\n",
        "5. Description (to save as `placeDesc`): String. Everything from under the first image up to \"know before you go\" (orange frame on the example image).\n",
        "6. Short Description (to save as `placeShortDesc`): String. Everything from the title and location up to the image (blue frame on the example image).\n",
        "7. Nearby Places (to save as `placeNearby`): Extract the names of all nearby places, but only keep unique values: List of Strings.\n",
        "8. Address of the place(to save as `placeAddress`): String.\n",
        "9. Latitud and Longitude of the place's location(to save as `placeAlt` and `placeLong`): Floats\n",
        "10. The username of the post editors (to save as `placeEditors`): List of Strings.\n",
        "11. Post publishing date (to save as `placePubDate`): datetime.\n",
        "12. The names of the lists that the place was included in (to save as `placeRelatedLists`): List of Strings.\n",
        "13. The names of the related places (to save as `placeRelatedPlaces`): List of Strings.\n",
        "14. The URL of the page of the place (to save as `placeURL`): String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vao0w9tx-MVA"
      },
      "outputs": [],
      "source": [
        "pages = sorted(os.listdir('/content/drive/MyDrive/ADM_HW_3/html_page')[1:], key = lambda x : int(x.split(\"_\")[1]))\n",
        "placeName = []\n",
        "placeTags = []\n",
        "numPeopleVisited = []\n",
        "numPeopleWant = []\n",
        "placeDesc = []\n",
        "placeShortDesc = []\n",
        "placeNearby = []\n",
        "placeAddress = []\n",
        "placeAlt = []\n",
        "placeLong = []\n",
        "placeEditors = []\n",
        "placePubDate = []\n",
        "placeRelatedLists = []\n",
        "placeRelatedPlaces = []\n",
        "placeURL = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uovNC1-0DCdr"
      },
      "outputs": [],
      "source": [
        "for i in pages:\n",
        "    htmls = os.listdir('/content/drive/MyDrive/ADM_HW_3/html_page'+\"/\"+str(i))\n",
        "    for j in range(1,1+len(htmls)):\n",
        "        file = open(\"/content/drive/MyDrive/ADM_HW_3/html_page/{}/{}.html\".format(i,18*(int(i.split(\"_\")[1])-1)+j), 'r', encoding=\"utf8\")\n",
        "        place = BeautifulSoup(file, 'lxml')\n",
        "        \n",
        "       #title\n",
        "        try:\n",
        "            t=place.find('meta', attrs = {'property':'og:title'})\n",
        "            t=t['content']\n",
        "            placeName.append(t)\n",
        "        except:\n",
        "            placeName.append('')\n",
        "\n",
        "        #description\n",
        "        try:\n",
        "            d=place.find(\"div\", class_ = 'DDP__body-copy').text.strip()\n",
        "            placeDesc.append(d)\n",
        "        except:\n",
        "            placeDesc.append('')\n",
        "\n",
        "        #shortdescription\n",
        "        try:\n",
        "            sd=place.find('meta', attrs = {'property':'og:description'})\n",
        "            sd=sd['content']\n",
        "            placeShortDesc.append(sd)\n",
        "        except:\n",
        "            placeShortDesc.append('')\n",
        "\n",
        "      #pubdate\n",
        "        try:\n",
        "            pdate=place.find('div', class_ = 'DDPContributor__name').text.strip()\n",
        "            placePubDate.append(pdate)\n",
        "        except:\n",
        "            placePubDate.append('')\n",
        "\n",
        "        #placealt\n",
        "        try:\n",
        "            pa=place.find('meta', attrs = {'property':'place:location:latitude'})\n",
        "            pa=pa['content']\n",
        "            placeAlt.append(pa)\n",
        "        except:\n",
        "            placeAlt.append('')\n",
        "            \n",
        "        #placelong\n",
        "        try:\n",
        "            pl=place.find('meta', attrs = {'property':'place:location:longitude'})\n",
        "            pl=pl['content']\n",
        "            placeLong.append(pl)\n",
        "        except:\n",
        "            placeLong.append('')            \n",
        "        #placeTags\n",
        "        try:\n",
        "            pt=place.find_all('a', {'class': 'itemTags__link js-item-tags-link'})\n",
        "            pt=[i.get('href').split('/categories/')[1] for i in pt]\n",
        "            placeTags.append(pt)\n",
        "        except:\n",
        "            placeTags.append('')     \n",
        "\n",
        "        #numPeopleVisited\n",
        "        try:\n",
        "            num_visitors = place.find_all('div', class_ = 'title-md item-action-count')[0].text.strip()\n",
        "            numPeopleVisited.append(num_visitors)\n",
        "        except:\n",
        "            numPeopleVisited.append('')\n",
        "            \n",
        "        # num peolpe want\n",
        "        try:\n",
        "            num_want = place.find_all('div', class_ = 'title-md item-action-count')[1].text.strip()\n",
        "            numPeopleWant.append(num_want)\n",
        "        except:\n",
        "            numPeopleWant.append('')\n",
        "         \n",
        "        #placeNearby\n",
        "        try:\n",
        "            pnb=place.find_all('div', {'class':'DDPageSiderailRecirc__item-title'})\n",
        "            pnb=[i.get_text() for i in pnb]   \n",
        "            placeNearby.append(pnb)\n",
        "        except:\n",
        "            placeNearby.append('')\n",
        "\n",
        "        #placeAddress\n",
        "        try:\n",
        "            pa=place.find_all('address', {'class':'DDPageSiderail__address'})[0]\n",
        "            pa=pa.find('div').get_text(separator = ' ').split('\\n')[0]\n",
        "            placeAddress.append(pa)\n",
        "        except:\n",
        "            placeAddress.append('')\n",
        "\n",
        "        #placeEditors\n",
        "        try:\n",
        "            pe=place.find_all('div', {'class': 'ugc-editor-icons'})\n",
        "            pe=[i.findChildren('a')[0].get('href') for i in pe]\n",
        "            pe=[j.split('/users/')[1] for j in pe]\n",
        "            placeEditors.append(pe)\n",
        "        except:\n",
        "            placeEditors.append('')\n",
        "\n",
        "        #placeRelatedLists\n",
        "        try:\n",
        "            prl=place.find_all('div', {\"data-gtm-template\" : \"DDP Footer Recirc Lists\"})[0]\n",
        "            prl=[i.text.strip() for i in prl.find_all('h3')]\n",
        "            placeRelatedLists.append(prl)\n",
        "        except:\n",
        "            placeRelatedLists.append('')\n",
        "\n",
        "        #placeRelatedPlaces\n",
        "        try:\n",
        "            prp=place.find_all('div', {'class':'CardRecircSection__title'})\n",
        "            prp=[i for i in prp if i.text == 'Related Places'][0]\n",
        "            prp=prp.find_all_next('div', {'class':'Card__action-btns vue-js-been-there-everywhere-place'})\n",
        "            prp=[j.get('data-place-title') for j in prp]\n",
        "            placeRelatedPlaces.append(prp)\n",
        "        except:\n",
        "            placeRelatedPlaces.append('')\n",
        "\n",
        "        #url\n",
        "        try:\n",
        "            u=place.find('meta', attrs = {'property':'og:url'})\n",
        "            u=u['content']\n",
        "            placeURL.append(u)\n",
        "        except:\n",
        "            placeURL.append('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCEAYPBGDVpx"
      },
      "outputs": [],
      "source": [
        "col = ['placeName','placeTags','numPeopleVisited','numPeopleWant','placeDesc','placeShortDesc','placeNearby','placeAddress',\n",
        "       'placeAlt','placeLong','placeEditors','placePubDate','placeRelatedLists','placeRelatedPlaces','placeURL']\n",
        "types = {'placeName' : 'object',\n",
        "         'placeTags' : 'object',\n",
        "         'numPeopleVisited' : 'object',\n",
        "         'numPeopleWant' : 'object',\n",
        "         'placeDesc' : 'object',\n",
        "         'placeShortDesc' : 'object',\n",
        "         'placeNearby' : 'object',\n",
        "         'placeAddress' : 'object',\n",
        "         'placeAlt' : 'int64',\n",
        "         'placeLong' : 'int64',\n",
        "         'placeEditors' : 'object',\n",
        "         'placePubDate' : 'datetime64',\n",
        "         'placeRelatedLists' : 'object',\n",
        "         'placeRelatedPlaces' : 'object',\n",
        "         'placeURL' : 'object'}\n",
        "data = pd.DataFrame(columns = col).astype(dtype = types) \n",
        "data.placeName = placeName \n",
        "data.placeTags = placeTags\n",
        "data.numPeopleVisited = numPeopleVisited\n",
        "data.numPeopleWant = numPeopleWant\n",
        "data.placeDesc = placeDesc \n",
        "data.placeShortDesc = placeShortDesc \n",
        "data.placePubDate = placePubDate\n",
        "data.placeNearby = placeNearby\n",
        "data.placeAddress = placeAddress\n",
        "data.placeAlt = placeAlt\n",
        "data.placeLong = placeLong\n",
        "data.placeEditors = placeEditors\n",
        "data.placePubDate = placePubDate\n",
        "data.placeRelatedLists = placeRelatedLists\n",
        "data.placeRelatedPlaces = placeRelatedPlaces\n",
        "data.placeURL = placeURL "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28wW8kwEDXPV"
      },
      "outputs": [],
      "source": [
        "# save the data in a single tsv file\n",
        "data = data.to_csv(\"/content/drive/MyDrive/ADM_HW_3/places.tsv\", sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "C9L6Eex8DfUb",
        "outputId": "c4475392-b5c9-4026-db2c-480a9d1cc625"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eefabe44-836c-4423-9fac-e6c3ae53b686\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>placeName</th>\n",
              "      <th>placeTags</th>\n",
              "      <th>numPeopleVisited</th>\n",
              "      <th>numPeopleWant</th>\n",
              "      <th>placeDesc</th>\n",
              "      <th>placeShortDesc</th>\n",
              "      <th>placeNearby</th>\n",
              "      <th>placeAddress</th>\n",
              "      <th>placeAlt</th>\n",
              "      <th>placeLong</th>\n",
              "      <th>placeEditors</th>\n",
              "      <th>placePubDate</th>\n",
              "      <th>placeRelatedLists</th>\n",
              "      <th>placeRelatedPlaces</th>\n",
              "      <th>placeURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>City Hall Station</td>\n",
              "      <td>['subways', 'subterranean', 'infrastructure', ...</td>\n",
              "      <td>1828.0</td>\n",
              "      <td>8579.0</td>\n",
              "      <td>The first New York City subway was built and o...</td>\n",
              "      <td>A beautiful and abandoned New York subway stat...</td>\n",
              "      <td>['African Burial Ground National Monument', 'T...</td>\n",
              "      <td>31 Centre St New York, New York, 10007 United ...</td>\n",
              "      <td>40.713400</td>\n",
              "      <td>-74.004600</td>\n",
              "      <td>['rebekah-otto', 'annetta-black']</td>\n",
              "      <td>May 8, 2010</td>\n",
              "      <td>['30 Unexpected Places to Have a Joyful Advent...</td>\n",
              "      <td>['Crystal Palace Subway', 'Moscow Metro Statio...</td>\n",
              "      <td>http://www.atlasobscura.com/places/city-hall-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Highgate Cemetery</td>\n",
              "      <td>['rivals-week', 'vampires', 'hoaxes', 'occult'...</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>8182.0</td>\n",
              "      <td>Opened in 1839, Highgate is one of London’s mo...</td>\n",
              "      <td>London's creepiest cemetery was once the site ...</td>\n",
              "      <td>[\"World's Largest Potted Plant\", 'Dick Whittin...</td>\n",
              "      <td>Swain's Lane, Highgate London, England, N6 Uni...</td>\n",
              "      <td>51.567536</td>\n",
              "      <td>-0.148290</td>\n",
              "      <td>['annetta-black']</td>\n",
              "      <td>August 9, 2014</td>\n",
              "      <td>[\"The World's Top 100 Wonders in 2018\", \"Londo...</td>\n",
              "      <td>['Jewett City Vampires', 'Tomb of the Mather F...</td>\n",
              "      <td>http://www.atlasobscura.com/places/highgate-ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Real-World Diagon Alley</td>\n",
              "      <td>['markets', 'film-locations', 'film']</td>\n",
              "      <td>3134.0</td>\n",
              "      <td>7567.0</td>\n",
              "      <td>The ornate 19th-century painted roof and cobbl...</td>\n",
              "      <td>This ornate Victorian marketplace was the sett...</td>\n",
              "      <td>['The Cornhill Devils ', \"London's Original an...</td>\n",
              "      <td>London, England, EC3V United Kingdom</td>\n",
              "      <td>51.512581</td>\n",
              "      <td>-0.083401</td>\n",
              "      <td>['meghanneal', '643fc779-d0c4-40f3-9fc2-363796...</td>\n",
              "      <td>August 1, 2016</td>\n",
              "      <td>['The Ultimate Guide to Stunning, Surprising, ...</td>\n",
              "      <td>['Rivendell', 'Bagdad Cafe', 'Gare de la Ciota...</td>\n",
              "      <td>http://www.atlasobscura.com/places/leadenhall-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Wave Organ</td>\n",
              "      <td>['sea-organ', 'aletrail', 'sounds', 'music', '...</td>\n",
              "      <td>2427.0</td>\n",
              "      <td>7406.0</td>\n",
              "      <td>Located on a jetty in the San Francisco Bay, t...</td>\n",
              "      <td>A huge musical instrument played by the ocean.</td>\n",
              "      <td>['Long Now Orrery', 'The Stern of the Briganti...</td>\n",
              "      <td>83 Marina Green Dr San Francisco, California, ...</td>\n",
              "      <td>37.808549</td>\n",
              "      <td>-122.440131</td>\n",
              "      <td>['mbison', 'catleast']</td>\n",
              "      <td>November 21, 2008</td>\n",
              "      <td>[\"Leonardo Nam's 16 Quirky Roadside Attraction...</td>\n",
              "      <td>['Sea Organ', 'Silent Green Kulturquartier', \"...</td>\n",
              "      <td>http://www.atlasobscura.com/places/wave-organ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Catacombes de Paris</td>\n",
              "      <td>['ossuaries', 'memento-mori', 'catacombs-and-c...</td>\n",
              "      <td>4444.0</td>\n",
              "      <td>7044.0</td>\n",
              "      <td>In 2004, Parisian police were assigned to do a...</td>\n",
              "      <td>The vast, legendary catacombs hold secrets muc...</td>\n",
              "      <td>['Sculptures de Décure', 'Arago Medallions', \"...</td>\n",
              "      <td>1 Place Denfert-Rochereau Paris, 75014 France</td>\n",
              "      <td>48.834329</td>\n",
              "      <td>2.332234</td>\n",
              "      <td>['cpilgrim', 'escape-zeppelin']</td>\n",
              "      <td>February 13, 2009</td>\n",
              "      <td>['19 Catacombs Sure to Tingle Your Spine', \"Th...</td>\n",
              "      <td>['Ossario di San Martino', 'Leuk Charnel House...</td>\n",
              "      <td>http://www.atlasobscura.com/places/catacombes-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eefabe44-836c-4423-9fac-e6c3ae53b686')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eefabe44-836c-4423-9fac-e6c3ae53b686 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eefabe44-836c-4423-9fac-e6c3ae53b686');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     placeName  \\\n",
              "0            City Hall Station   \n",
              "1            Highgate Cemetery   \n",
              "2  The Real-World Diagon Alley   \n",
              "3               The Wave Organ   \n",
              "4          Catacombes de Paris   \n",
              "\n",
              "                                           placeTags  numPeopleVisited  \\\n",
              "0  ['subways', 'subterranean', 'infrastructure', ...            1828.0   \n",
              "1  ['rivals-week', 'vampires', 'hoaxes', 'occult'...            2617.0   \n",
              "2              ['markets', 'film-locations', 'film']            3134.0   \n",
              "3  ['sea-organ', 'aletrail', 'sounds', 'music', '...            2427.0   \n",
              "4  ['ossuaries', 'memento-mori', 'catacombs-and-c...            4444.0   \n",
              "\n",
              "   numPeopleWant                                          placeDesc  \\\n",
              "0         8579.0  The first New York City subway was built and o...   \n",
              "1         8182.0  Opened in 1839, Highgate is one of London’s mo...   \n",
              "2         7567.0  The ornate 19th-century painted roof and cobbl...   \n",
              "3         7406.0  Located on a jetty in the San Francisco Bay, t...   \n",
              "4         7044.0  In 2004, Parisian police were assigned to do a...   \n",
              "\n",
              "                                      placeShortDesc  \\\n",
              "0  A beautiful and abandoned New York subway stat...   \n",
              "1  London's creepiest cemetery was once the site ...   \n",
              "2  This ornate Victorian marketplace was the sett...   \n",
              "3     A huge musical instrument played by the ocean.   \n",
              "4  The vast, legendary catacombs hold secrets muc...   \n",
              "\n",
              "                                         placeNearby  \\\n",
              "0  ['African Burial Ground National Monument', 'T...   \n",
              "1  [\"World's Largest Potted Plant\", 'Dick Whittin...   \n",
              "2  ['The Cornhill Devils ', \"London's Original an...   \n",
              "3  ['Long Now Orrery', 'The Stern of the Briganti...   \n",
              "4  ['Sculptures de Décure', 'Arago Medallions', \"...   \n",
              "\n",
              "                                        placeAddress   placeAlt   placeLong  \\\n",
              "0  31 Centre St New York, New York, 10007 United ...  40.713400  -74.004600   \n",
              "1  Swain's Lane, Highgate London, England, N6 Uni...  51.567536   -0.148290   \n",
              "2               London, England, EC3V United Kingdom  51.512581   -0.083401   \n",
              "3  83 Marina Green Dr San Francisco, California, ...  37.808549 -122.440131   \n",
              "4      1 Place Denfert-Rochereau Paris, 75014 France  48.834329    2.332234   \n",
              "\n",
              "                                        placeEditors       placePubDate  \\\n",
              "0                  ['rebekah-otto', 'annetta-black']        May 8, 2010   \n",
              "1                                  ['annetta-black']     August 9, 2014   \n",
              "2  ['meghanneal', '643fc779-d0c4-40f3-9fc2-363796...     August 1, 2016   \n",
              "3                             ['mbison', 'catleast']  November 21, 2008   \n",
              "4                    ['cpilgrim', 'escape-zeppelin']  February 13, 2009   \n",
              "\n",
              "                                   placeRelatedLists  \\\n",
              "0  ['30 Unexpected Places to Have a Joyful Advent...   \n",
              "1  [\"The World's Top 100 Wonders in 2018\", \"Londo...   \n",
              "2  ['The Ultimate Guide to Stunning, Surprising, ...   \n",
              "3  [\"Leonardo Nam's 16 Quirky Roadside Attraction...   \n",
              "4  ['19 Catacombs Sure to Tingle Your Spine', \"Th...   \n",
              "\n",
              "                                  placeRelatedPlaces  \\\n",
              "0  ['Crystal Palace Subway', 'Moscow Metro Statio...   \n",
              "1  ['Jewett City Vampires', 'Tomb of the Mather F...   \n",
              "2  ['Rivendell', 'Bagdad Cafe', 'Gare de la Ciota...   \n",
              "3  ['Sea Organ', 'Silent Green Kulturquartier', \"...   \n",
              "4  ['Ossario di San Martino', 'Leuk Charnel House...   \n",
              "\n",
              "                                            placeURL  \n",
              "0  http://www.atlasobscura.com/places/city-hall-s...  \n",
              "1  http://www.atlasobscura.com/places/highgate-ce...  \n",
              "2  http://www.atlasobscura.com/places/leadenhall-...  \n",
              "3      http://www.atlasobscura.com/places/wave-organ  \n",
              "4  http://www.atlasobscura.com/places/catacombes-...  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read the first lines of the csv file \n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ADM_HW_3/places.tsv\", sep='\\t')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJEwEg2Xe54x"
      },
      "outputs": [],
      "source": [
        "# create a directory where to save the tsv files\n",
        "os.makedirs('/content/drive/MyDrive/ADM_HW_3/tsv_files') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAXIeJ5Se6hT"
      },
      "outputs": [],
      "source": [
        "# for each place we create a place_i.tsv file \n",
        "\n",
        "filename='/content/drive/MyDrive/ADM_HW_3/tsv_files/places'\n",
        "n = 1\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if i % 1 == 0:\n",
        "        data = (data[i:i+1])\n",
        "        data.to_csv(f'{filename}_{n}.tsv', index=False)\n",
        "        n += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fskFMQk-U8q"
      },
      "source": [
        "## 2. Search Engine\n",
        "\n",
        "Now, we want to create two different Search Engines that, given as input a query, return the places that match the query.\n",
        "\n",
        "First, you must pre-process all the information collected for each place by:\n",
        "\n",
        "1. Removing stopwords\n",
        "\n",
        "2. Removing punctuation\n",
        "\n",
        "3. Stemming\n",
        "\n",
        "4. Anything else you think it's needed\n",
        "\n",
        "For this purpose, you can use the [nltk library](https://www.nltk.org).\n",
        "\n",
        "### 2.1. Conjunctive query\n",
        "\n",
        "For the first version of the search engine, we narrow our interest to the description of each place. It means that you will evaluate queries only concerning the place's description.\n",
        "\n",
        "__Note__: You should use the longer description `placeDesc` column and not the short description `placeShortDesc`.\n",
        "\n",
        "#### 2.1.1) Create your index!\n",
        "\n",
        "Before building the index,\n",
        "\n",
        "$\\bullet$ Create a file named vocabulary, in the format you prefer, that maps each word to an integer (term_id).\n",
        "\n",
        "Then, the first brick of your homework is to create the Inverted Index. It will be a dictionary in this format:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "term_id_1:[document_1, document_2, document_4],\n",
        "term_id_2:[document_1, document_3, document_5, document_6],\n",
        "...}\n",
        "```\n",
        "\n",
        "where document_i is the id of a document that contains that specific word.\n",
        "\n",
        "__Hint__: Since you do not want to compute the inverted index every time you use the Search Engine, it is worth thinking about storing it in a separate file and loading it in memory when needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2rb3hWy_KX2"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/ADM_HW_3/places.tsv\", sep='\\t', usecols=['placeName', 'placeDesc', 'placeURL'])\n",
        "descriptions = data.placeDesc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F914y89aD56r"
      },
      "outputs": [],
      "source": [
        "# function to clean the documents\n",
        "def cleanupDoc(s):\n",
        "    stopset = set(stopwords.words('english'))\n",
        "    s = s.replace(\"'\", \" \")\n",
        "    s = s.replace(\"\\n\", \" \")\n",
        "    tokens = nltk.word_tokenize(s)\n",
        "    cleanup = [token.lower() for token in tokens if token.lower() not in stopset and len(token)>2]\n",
        "    ps = PorterStemmer()\n",
        "    for i in range(len(cleanup)):\n",
        "        cleanup[i] = ps.stem(cleanup[i])\n",
        "    return cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTcYAMjPD6vC"
      },
      "outputs": [],
      "source": [
        "# join togheter all the descriptions and then apply the function to do the cleaning\n",
        "list_word = list(descriptions)\n",
        "words = ''.join(map(str, list_word))\n",
        "cleaned_words = cleanupDoc(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQtofFFFD_1r"
      },
      "outputs": [],
      "source": [
        "# with all the cleaned words (taken one time) I create the vocabulary\n",
        "vocabulary = dict([(y, x+1) for x, y in enumerate(sorted(set(cleaned_words)))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2r4DIaPECyf"
      },
      "outputs": [],
      "source": [
        "# to save as a file the vocabulary\n",
        "with open(\"/content/drive/MyDrive/ADM_HW_3/vocabulary.pkl\", \"wb\") as file:\n",
        "    pickle.dump(vocabulary, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8gU6tM5EEHa"
      },
      "outputs": [],
      "source": [
        "# to import the vocabulary\n",
        "with open(\"/content/drive/MyDrive/ADM_HW_3/vocabulary.pkl\", \"rb\") as file:\n",
        "    vocabulary = pickle.load(file) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh45kZNsEELD"
      },
      "outputs": [],
      "source": [
        "# create a list with all the cleaned descriptions\n",
        "cleaned_desc = []\n",
        "for desc in list_word:\n",
        "    cleaned_desc.append(cleanupDoc(str(desc)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ERBrj-eEEOt"
      },
      "outputs": [],
      "source": [
        "# inverted index as a dict of set\n",
        "inv_index = defaultdict(set)\n",
        "\n",
        "N = len(cleaned_desc)\n",
        "# take the word and the mapped word\n",
        "for k, v in tqdm(vocabulary.items()):\n",
        "    # goes trough every description\n",
        "    for i in range(N):\n",
        "        # check if the word is in the descrption and in that case add it to the inverted index\n",
        "        if k in cleaned_desc[i]:\n",
        "            inv_index[v].add(i) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CamF8_LREESW"
      },
      "outputs": [],
      "source": [
        "# to save as a file the inverted index\n",
        "with open(\"/content/drive/MyDrive/ADM_HW_3/inverted_index.pkl\", \"wb\") as file1:\n",
        "    pickle.dump(inv_index, file1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcGmBF3_EWJD"
      },
      "outputs": [],
      "source": [
        "# to import the inverted index\n",
        "with open(\"/content/drive/MyDrive/ADM_HW_3/inverted_index.pkl\", \"rb\") as file1:\n",
        "    inv_index = pickle.load(file1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eJlRLZs_L97"
      },
      "source": [
        "#### 2.1.2) Execute the query\n",
        "\n",
        "Given a query input by the user, for example:\n",
        "\n",
        "```\n",
        "american museum\n",
        "```\n",
        "\n",
        "The Search Engine is supposed to return a list of documents.\n",
        "\n",
        "__What documents do we want?__\n",
        "\n",
        "Since we are dealing with conjunctive queries (AND), each returned document should contain all the words in the query. The final output of the query must return, if present, the following information for each of the selected documents:\n",
        "\n",
        "- `placeName`\n",
        "- `placeDesc`\n",
        "- `placeURL`\n",
        "\n",
        "If everything works well in this step, you can go to the next point and make your Search Engine more complex and better at answering queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vG8EDWa_dNZ"
      },
      "outputs": [],
      "source": [
        "def search_engine_v1(query, data):\n",
        "    # cleaning of the query\n",
        "    query_list = cleanupDoc(query)\n",
        "    docs = dict()\n",
        "    try:\n",
        "        for word in query_list:\n",
        "            # take the corrispondent index of the word\n",
        "            mapped_word = vocabulary[word]\n",
        "            # find in the inverted index all the docs where the word appears\n",
        "            matches = inv_index.get(mapped_word)\n",
        "            # add the documents founds to the dictionary\n",
        "            docs[mapped_word] = matches\n",
        "    except:\n",
        "        return print('One word or more are not present in any descriptions')\n",
        "    # to find the intersection: list all the documets found\n",
        "    all_docs = list(docs.values())\n",
        "    # assign the docouments of the first word to a variable\n",
        "    first_query_word = all_docs[0]\n",
        "    # assign the docouments of the other words to a variable\n",
        "    rest_query_word = all_docs[1:]\n",
        "    # take only the documents that appear in every query word\n",
        "    out = [t for t in set(first_query_word) if all(t in q for q in rest_query_word)]\n",
        "    return data.loc[out]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33ffOT_4Ed7V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "543dfad5-8027-4978-dd3f-926822e39253"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   placeName  \\\n",
              "4098             Hugh Mercer Apothecary Shop   \n",
              "2058                          Soumaya Museum   \n",
              "2080              Gillette Castle State Park   \n",
              "2081              Mitsitam Native Foods Cafe   \n",
              "2084              Stained Glass at Navy Pier   \n",
              "...                                      ...   \n",
              "6104              99s Museum of Women Pilots   \n",
              "4059  Pinson Mounds State Archeological Park   \n",
              "4078            World's Largest Shuttlecocks   \n",
              "4081                McNutt Sculpture Garden    \n",
              "6140       Martha, the Last Passenger Pigeon   \n",
              "\n",
              "                                              placeDesc  \\\n",
              "4098  Hugh Mercer was a Scot, a warrior, a friend of...   \n",
              "2058  Housing a whopping 66,000 pieces of predominan...   \n",
              "2080  High above the Connecticut River, Gillette Cas...   \n",
              "2081  A visit to the National Mall in Washington, D....   \n",
              "2084  The very first American exhibit dedicated sole...   \n",
              "...                                                 ...   \n",
              "6104  Women pilots had been barred from participatin...   \n",
              "4059  Located in Madison County, Tennessee, this par...   \n",
              "4078  Across the expansive grounds of the Nelson-Atk...   \n",
              "4081  A hidden sculpture garden exists just off the ...   \n",
              "6140  When Europeans began settling in the New World...   \n",
              "\n",
              "                                               placeURL  \n",
              "4098  http://www.atlasobscura.com/places/hugh-mercer...  \n",
              "2058  http://www.atlasobscura.com/places/soumaya-museum  \n",
              "2080  http://www.atlasobscura.com/places/gillettes-c...  \n",
              "2081  http://www.atlasobscura.com/places/mitsitam-na...  \n",
              "2084  http://www.atlasobscura.com/places/stained-gla...  \n",
              "...                                                 ...  \n",
              "6104  http://www.atlasobscura.com/places/museum-of-w...  \n",
              "4059  http://www.atlasobscura.com/places/pinson-moun...  \n",
              "4078  http://www.atlasobscura.com/places/world-s-lar...  \n",
              "4081  http://www.atlasobscura.com/places/mcnutt-scul...  \n",
              "6140  http://www.atlasobscura.com/places/martha-the-...  \n",
              "\n",
              "[221 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d875b8bb-e953-485d-9df8-eaed1bc525fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>placeName</th>\n",
              "      <th>placeDesc</th>\n",
              "      <th>placeURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4098</th>\n",
              "      <td>Hugh Mercer Apothecary Shop</td>\n",
              "      <td>Hugh Mercer was a Scot, a warrior, a friend of...</td>\n",
              "      <td>http://www.atlasobscura.com/places/hugh-mercer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2058</th>\n",
              "      <td>Soumaya Museum</td>\n",
              "      <td>Housing a whopping 66,000 pieces of predominan...</td>\n",
              "      <td>http://www.atlasobscura.com/places/soumaya-museum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2080</th>\n",
              "      <td>Gillette Castle State Park</td>\n",
              "      <td>High above the Connecticut River, Gillette Cas...</td>\n",
              "      <td>http://www.atlasobscura.com/places/gillettes-c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081</th>\n",
              "      <td>Mitsitam Native Foods Cafe</td>\n",
              "      <td>A visit to the National Mall in Washington, D....</td>\n",
              "      <td>http://www.atlasobscura.com/places/mitsitam-na...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2084</th>\n",
              "      <td>Stained Glass at Navy Pier</td>\n",
              "      <td>The very first American exhibit dedicated sole...</td>\n",
              "      <td>http://www.atlasobscura.com/places/stained-gla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>99s Museum of Women Pilots</td>\n",
              "      <td>Women pilots had been barred from participatin...</td>\n",
              "      <td>http://www.atlasobscura.com/places/museum-of-w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4059</th>\n",
              "      <td>Pinson Mounds State Archeological Park</td>\n",
              "      <td>Located in Madison County, Tennessee, this par...</td>\n",
              "      <td>http://www.atlasobscura.com/places/pinson-moun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4078</th>\n",
              "      <td>World's Largest Shuttlecocks</td>\n",
              "      <td>Across the expansive grounds of the Nelson-Atk...</td>\n",
              "      <td>http://www.atlasobscura.com/places/world-s-lar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4081</th>\n",
              "      <td>McNutt Sculpture Garden</td>\n",
              "      <td>A hidden sculpture garden exists just off the ...</td>\n",
              "      <td>http://www.atlasobscura.com/places/mcnutt-scul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6140</th>\n",
              "      <td>Martha, the Last Passenger Pigeon</td>\n",
              "      <td>When Europeans began settling in the New World...</td>\n",
              "      <td>http://www.atlasobscura.com/places/martha-the-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>221 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d875b8bb-e953-485d-9df8-eaed1bc525fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d875b8bb-e953-485d-9df8-eaed1bc525fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d875b8bb-e953-485d-9df8-eaed1bc525fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "query = 'american museum'\n",
        "search_engine_v1(query, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZTheg6I_daq"
      },
      "source": [
        "### 2.2) Conjunctive query & Ranking score\n",
        "\n",
        "For the second search engine, given a query, we want to get the top-k (the choice of k it's up to you!) documents related to the query. In particular:\n",
        "\n",
        "- Find all the documents that contain all the words in the query.\n",
        "- Sort them by their similarity with the query.\n",
        "\n",
        "$\\bullet$ Return in output k documents, or all the documents with non-zero similarity with the query when the results are less than k. You must use a heap data structure (you can use Python libraries) for maintaining the _top-k_ documents.\n",
        "\n",
        "To solve this task, you must use the _tfIdf_ score and the _Cosine similarity_. The field to consider is still the `placeDesc`. Let's see how.\n",
        "\n",
        "#### 2.2.1) Inverted index\n",
        "\n",
        "Your second Inverted Index must be of this format:\n",
        "\n",
        "```\n",
        "{\n",
        "term_id_1:[(document1, tfIdf_{term,document1}), (document2, tfIdf_{term,document2}), (document4, tfIdf_{term,document4}), ...],\n",
        "term_id_2:[(document1, tfIdf_{term,document1}), (document3, tfIdf_{term,document3}), (document5, tfIdf_{term,document5}), (document6, tfIdf_{term,document6}), ...],\n",
        "...}\n",
        "```\n",
        "\n",
        "Practically, for each word, you want the list of documents in which it is contained and the relative _tfIdf_ score.\n",
        "\n",
        "__Tip:__ _TfIdf_ values are invariant for the query. Due to this reason, you can precalculate and store them accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lokjz2FGAEf0",
        "outputId": "084b2366-a3b3-4d52-e688-21b23f229890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56254/56254 [25:17<00:00, 37.08it/s]\n"
          ]
        }
      ],
      "source": [
        "# second inverted index with tfidf as a dictionary of dictionary\n",
        "inv_index_tfidf = defaultdict(dict)\n",
        "\n",
        "N = len(cleaned_desc)\n",
        "# take the word and the mapped word\n",
        "for k, i in tqdm(vocabulary.items()):\n",
        "    # number of docs that contains word i\n",
        "    df_i = len(inv_index[i])\n",
        "    # goes trough every description\n",
        "    for j in range(N):\n",
        "        # check if the word k is in the cleaned desc j\n",
        "        if k in cleaned_desc[j]:\n",
        "            # relative frequency of word k in description j\n",
        "            tf_i_j = cleaned_desc[j].count(k)/len(cleaned_desc[j])\n",
        "            # tfidf\n",
        "            w_i_j = tf_i_j * np.log(N/df_i)\n",
        "            # assign doc_id and tdifd to the word i\n",
        "            inv_index_tfidf[i].update({j: w_i_j})\n",
        "\n",
        "# I want to save in the last row of the inverted index also the docs norms\n",
        "# I store the tfidf in a matrix to semplify the next calculations\n",
        "tfidf_matrix = np.zeros((len(vocabulary), N))\n",
        "for i in range(len(vocabulary)):\n",
        "    tfidf_matrix[i, list(inv_index_tfidf[i].keys())] = list(inv_index_tfidf[i].values())\n",
        "# calculate the norm of every docs\n",
        "for j in range(N):\n",
        "    norm = np.linalg.norm(tfidf_matrix[:, j])\n",
        "    inv_index_tfidf['norm'].update({j: norm})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqOYIJUqEtec"
      },
      "outputs": [],
      "source": [
        "# to save as a file the second inverted index\n",
        "with open(\"/content/drive/MyDrive/ADM_HW_3/inverted_index_tfidf.pkl\", \"wb\") as file2:\n",
        "    pickle.dump(inv_index_tfidf, file2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lom61KQEEtoC"
      },
      "outputs": [],
      "source": [
        "# to import the second inverted index\n",
        "with open(\"/content/drive/MyDrive/ADM_HW_3/inverted_index_tfidf.pkl\", \"rb\") as file2:\n",
        "    inv_index_tfidf = pickle.load(file2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2weahWOAExf"
      },
      "source": [
        "#### 2.2.2) Execute the query\n",
        "\n",
        "In this new setting, given a query, you get the proper documents (i.e., those containing all the query's words) and sort them according to their similarity to the query. For this purpose, as the scoring function, we will use the Cosine Similarity concerning the _tfIdf_ representations of the documents.\n",
        "\n",
        "Given a query input by the user, for example:\n",
        "\n",
        "```\n",
        "american museum\n",
        "```\n",
        "\n",
        "The search engine is supposed to return a list of documents, ranked by their Cosine Similarity to the query entered in the input.\n",
        "\n",
        "More precisely, the output must contain:\n",
        "\n",
        "- `placeName`\n",
        "- `placeDesc`\n",
        "- `placeURL`\n",
        "- The similarity score of the documents with respect to the query (float value between 0 and 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrYgQckWFKSF"
      },
      "outputs": [],
      "source": [
        "data3 = pd.read_csv(\"/content/drive/MyDrive/ADM_HW_3/places.tsv\", sep='\\t', \n",
        "                    usecols=['placeName', 'placeDesc', 'numPeopleVisited', 'numPeopleWant',\n",
        "                             'placeAddress', 'placeAlt', 'placeLong', 'placeURL'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZIOtM67AjUN"
      },
      "outputs": [],
      "source": [
        "def search_engine_v2(query, data, n=10):\n",
        "    # cleaning of the query\n",
        "    query_list = cleanupDoc(query)\n",
        "    # initialize the dictionary that will contain the documents in which the words of the query and its tdidf appear\n",
        "    docs = dict()\n",
        "    # initialize the dictionary to calculate the tfidf of the query query\n",
        "    query_tfidf = dict()\n",
        "    N = len(cleaned_desc)\n",
        "    try:\n",
        "        for word in query_list:\n",
        "            # take the corrispondent index of the word\n",
        "            mapped_word = vocabulary[word]\n",
        "            # find in the inv_index_tfidf all the docs where the word appears\n",
        "            matches = inv_index_tfidf[mapped_word]\n",
        "            # add the documents founds to the dictionary\n",
        "            docs[mapped_word] = matches\n",
        "            # calculate the tfidf for the query word\n",
        "            tf_i_query = query_list.count(word)\n",
        "            idf_i_query = len(inv_index_tfidf[mapped_word])\n",
        "            query_tfidf[mapped_word] = tf_i_query * np.log(N/idf_i_query)\n",
        "              \n",
        "    except:\n",
        "        return print('One word or more are not present in any documents')\n",
        "    \n",
        "    # to find the intersection: list all the docs found\n",
        "    all_docs_tfidf = list(docs.values())\n",
        "    all_docs = [list(all_docs_tfidf[x].keys()) for x in range(len(all_docs_tfidf))]\n",
        "    # assign docs of the first word to a variable\n",
        "    first_query_word = all_docs[0]\n",
        "    # assign docs of the other words to a variable\n",
        "    rest_query_word = all_docs[1:]\n",
        "    # take only the docs that appear in every query word\n",
        "    commons_docs = [t for t in set(first_query_word) if all(t in q for q in rest_query_word)]\n",
        "    \n",
        "    # take the norm of the commons docs\n",
        "    docs_norm = inv_index_tfidf['norm']\n",
        "    # initialize the dict that I will use to calculate the cosine similarity\n",
        "    prodotti_query_i = defaultdict(dict)\n",
        "    \n",
        "    # calculate the norm of the query --- it is optional so I will not use it\n",
        "    # query_norm = np.linalg.norm(list(query_tfidf.values()))\n",
        "    \n",
        "    # initialize the heap\n",
        "    top_n = []\n",
        "    heapq.heapify(top_n)\n",
        "\n",
        "    for doc in commons_docs:\n",
        "        prodotti = []\n",
        "        # take the norm of doc\n",
        "        doc_norm = docs_norm[doc]\n",
        "        for word in set(query_list):\n",
        "            # take the mapped word\n",
        "            mapped_word = vocabulary[word]\n",
        "            # find the mapped word in the inv_index_tfidf\n",
        "            step1 = inv_index_tfidf[mapped_word]\n",
        "            # take the value of the tdidf\n",
        "            step2 = step1[doc]\n",
        "            # compute the products\n",
        "            prodotti.append(query_tfidf[mapped_word]*step2)\n",
        "        # calculate the cosine similarity\n",
        "        cos_sim_doc = (sum(prodotti)/(doc_norm), doc)\n",
        "        # until the heap contains less than n docs it will only do the push, then it will do pushpop\n",
        "        if len(top_n) < n:\n",
        "            heapq.heappush(top_n, cos_sim_doc)\n",
        "        else:\n",
        "            heapq.heappushpop(top_n, cos_sim_doc)\n",
        "                \n",
        "    # now I want to associate the similarity the the corrispondent doc in the df\n",
        "    n_larg_dict = dict()\n",
        "    for score, position in top_n:\n",
        "        n_larg_dict[position] = score\n",
        "    new_data = data[data.index.isin(n_larg_dict.keys())]\n",
        "    # inserting a column for the similarity\n",
        "    new_data.insert(5, \"Similarity\", \" \")\n",
        "    for i in new_data.index:\n",
        "        new_data.Similarity[i] = n_larg_dict[i]\n",
        "    \n",
        "    return new_data[['placeName', 'placeDesc', 'placeURL', 'Similarity']].sort_values(by=['Similarity'], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poQnL3WkEzmb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "51da1701-2baa-4346-dd10-4a6631e2fe08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              placeName  \\\n",
              "6216                    Sweet Home Cafe   \n",
              "141                 Museum of the Weird   \n",
              "1205  Harvard Museum of Natural History   \n",
              "6209             Siriraj Medical Museum   \n",
              "4460            American Writers Museum   \n",
              "1894       National World War II Museum   \n",
              "2738             Museum of Mourning Art   \n",
              "2665               Milwaukee Art Museum   \n",
              "6862                Indian Steps Museum   \n",
              "1385           Glore Psychiatric Museum   \n",
              "\n",
              "                                              placeDesc  \\\n",
              "6216  Thomas Downing was the oyster king. In 19th-ce...   \n",
              "141   The dime or dime store museum is by all accoun...   \n",
              "1205  Collecting three different institutions into o...   \n",
              "6209  The Siriraj Medical Museum abounds with medica...   \n",
              "4460  The American Writers Museum—tucked away on the...   \n",
              "1894  Perhaps once thought too narrowly focused, thi...   \n",
              "2738  Mourning and personal response to death are un...   \n",
              "2665  Like the Guggenheim in New York and the Oaklan...   \n",
              "6862  Constructed by a local lawyer from 1908-1912, ...   \n",
              "1385  Located in St. Joseph, Missouri, the Glore Psy...   \n",
              "\n",
              "                                               placeURL Similarity  \n",
              "6216  http://www.atlasobscura.com/places/sweet-home-...   0.729257  \n",
              "141     http://www.atlasobscura.com/places/museum-weird   0.631863  \n",
              "1205  http://www.atlasobscura.com/places/harvard-mus...   0.610889  \n",
              "6209  http://www.atlasobscura.com/places/siriraj-med...   0.543366  \n",
              "4460  http://www.atlasobscura.com/places/american-wr...   0.518324  \n",
              "1894  http://www.atlasobscura.com/places/national-wo...   0.497762  \n",
              "2738  http://www.atlasobscura.com/places/museum-of-m...   0.491534  \n",
              "2665  http://www.atlasobscura.com/places/milwaukee-a...   0.471093  \n",
              "6862  http://www.atlasobscura.com/places/indian-step...    0.46696  \n",
              "1385  http://www.atlasobscura.com/places/glore-psych...   0.465216  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c788e4d8-6891-4c40-8be6-6ea0baca4fd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>placeName</th>\n",
              "      <th>placeDesc</th>\n",
              "      <th>placeURL</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6216</th>\n",
              "      <td>Sweet Home Cafe</td>\n",
              "      <td>Thomas Downing was the oyster king. In 19th-ce...</td>\n",
              "      <td>http://www.atlasobscura.com/places/sweet-home-...</td>\n",
              "      <td>0.729257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>Museum of the Weird</td>\n",
              "      <td>The dime or dime store museum is by all accoun...</td>\n",
              "      <td>http://www.atlasobscura.com/places/museum-weird</td>\n",
              "      <td>0.631863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1205</th>\n",
              "      <td>Harvard Museum of Natural History</td>\n",
              "      <td>Collecting three different institutions into o...</td>\n",
              "      <td>http://www.atlasobscura.com/places/harvard-mus...</td>\n",
              "      <td>0.610889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6209</th>\n",
              "      <td>Siriraj Medical Museum</td>\n",
              "      <td>The Siriraj Medical Museum abounds with medica...</td>\n",
              "      <td>http://www.atlasobscura.com/places/siriraj-med...</td>\n",
              "      <td>0.543366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4460</th>\n",
              "      <td>American Writers Museum</td>\n",
              "      <td>The American Writers Museum—tucked away on the...</td>\n",
              "      <td>http://www.atlasobscura.com/places/american-wr...</td>\n",
              "      <td>0.518324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>National World War II Museum</td>\n",
              "      <td>Perhaps once thought too narrowly focused, thi...</td>\n",
              "      <td>http://www.atlasobscura.com/places/national-wo...</td>\n",
              "      <td>0.497762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2738</th>\n",
              "      <td>Museum of Mourning Art</td>\n",
              "      <td>Mourning and personal response to death are un...</td>\n",
              "      <td>http://www.atlasobscura.com/places/museum-of-m...</td>\n",
              "      <td>0.491534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2665</th>\n",
              "      <td>Milwaukee Art Museum</td>\n",
              "      <td>Like the Guggenheim in New York and the Oaklan...</td>\n",
              "      <td>http://www.atlasobscura.com/places/milwaukee-a...</td>\n",
              "      <td>0.471093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6862</th>\n",
              "      <td>Indian Steps Museum</td>\n",
              "      <td>Constructed by a local lawyer from 1908-1912, ...</td>\n",
              "      <td>http://www.atlasobscura.com/places/indian-step...</td>\n",
              "      <td>0.46696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1385</th>\n",
              "      <td>Glore Psychiatric Museum</td>\n",
              "      <td>Located in St. Joseph, Missouri, the Glore Psy...</td>\n",
              "      <td>http://www.atlasobscura.com/places/glore-psych...</td>\n",
              "      <td>0.465216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c788e4d8-6891-4c40-8be6-6ea0baca4fd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c788e4d8-6891-4c40-8be6-6ea0baca4fd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c788e4d8-6891-4c40-8be6-6ea0baca4fd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "query = 'american museum'\n",
        "num_docs_retrieved = 10\n",
        "search_engine_v2(query, data3, n=num_docs_retrieved)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVIek8fuAjnf"
      },
      "source": [
        "## 3. Define a new score!\n",
        "\n",
        "Now it's your turn. Build a new metric to rank places based on the queries of their users.\n",
        "\n",
        "In this scenario, a single user can give input more information than a single textual query, so you need to consider all this information and think of a creative and logical way to answer the user's requests.\n",
        "\n",
        "Practically:\n",
        "\n",
        "1. The user will enter a text query. As a starting point, get the query-related documents by exploiting the search engine of Step 3.1.\n",
        "\n",
        "2. Once you have the documents, you need to sort them according to your new score. In this step, you won't have any more to take into account just the plot of the documents; you must use the remaining variables in your dataset (or new possible variables that you can create from the existing ones). You must use a heap data structure (you can use Python libraries) for maintaining the top-k documents.\n",
        "\n",
        "_Q: How to sort them? A: Allow the user to specify more information that you find in the documents and define a new metric that ranks the results based on the new request. You can also use other information regarding the place to score some places above others._\n",
        "\n",
        "__N.B.:__ You have to define a scoring function, not a filter!\n",
        "\n",
        "The output, must contain:\n",
        "\n",
        "- `placeName`\n",
        "- `placeDesc`\n",
        "- `placeURL`\n",
        "\n",
        "The __new__ similarity score of the documents with respect to the query\n",
        "\n",
        "Are the results you obtain better than with the previous scoring function? __Explain and compare results.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSE-hbDTMsAo"
      },
      "source": [
        "***\n",
        "\n",
        "For this search engine the user is allowed to enter a text query, the name of a city and how many places to be retrieved.\\\n",
        "The search engine will: \n",
        "- find all the places where all the query words appear\n",
        "- calculate the cosine similarity\n",
        "- calculate for each place a normalized distance from the city specified\n",
        "- take the normalized number of people that want to visited that place\n",
        "- calculate a new similarity like an average of the 3\n",
        "- retrieve the top n similar places\n",
        "\n",
        "To find the coordinates of a city given a name I used geocoder and I created the API key here: https://www.microsoft.com/en-us/maps/create-a-bing-maps-key?wa=wsignin1.0#freeTab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-S6k94tA_vA"
      },
      "outputs": [],
      "source": [
        "def search_engine_v3(query, city, data, n=10, coord=False):\n",
        "    # to normalize the distances I use half of the circumference of the Earth\n",
        "    half_circ = 40075/2\n",
        "    # find the lat and long of the city requested\n",
        "    query_coord = geocoder.bing(city, key='AkVkWjzdeEY-SkdKMts3cJvq6uPcItl51RaA02HNdiCKrHCG6iix_oXI8KptUxci').json\n",
        "    query_coord_tuple = (query_coord['lat'], query_coord['lng'])\n",
        "    # I use the second search engine to get the cos_sim but with n=n*10 because after applying the second similarity some places will change position\n",
        "    step1 = search_engine_v2(query, data, n=n*10)    \n",
        "    # initialize the heap structure\n",
        "    top_n = []\n",
        "    heapq.heapify(top_n)\n",
        "    for i in step1.index:\n",
        "        # create a tuple with the coordinates\n",
        "        place_coord_tuple = (data.placeAlt[i], data.placeLong[i])\n",
        "        # I calculate the normalized distance and I take the square of it the discriminate more\n",
        "        distance = np.square(1-hs.haversine(query_coord_tuple, place_coord_tuple)/half_circ)\n",
        "        # I calculate the normalized number of numPeopleWant and I take the square root to discriminate less\n",
        "        popularity = np.sqrt(data.numPeopleWant[i]/np.max(data.numPeopleWant))\n",
        "        # new similarity like the average of the 3\n",
        "        new_similarity = (step1.Similarity[i] + distance + popularity) / 3\n",
        "        new_metric = (new_similarity, i)\n",
        "        # store in the heap\n",
        "        if len(top_n)<=n:\n",
        "            heapq.heappush(top_n, new_metric)\n",
        "        else:\n",
        "            heapq.heappushpop(top_n, new_metric)\n",
        "\n",
        "    # now I want to associate the similarity the the corrispondent doc in the df\n",
        "    n_larg_dict = dict()\n",
        "    for score, position in top_n:\n",
        "        n_larg_dict[position] = score\n",
        "    new_data = data[data.index.isin(n_larg_dict.keys())]\n",
        "    new_data.insert(6, \"new_similarity\", \" \")\n",
        "    for i in new_data.index:\n",
        "        new_data.new_similarity[i] = n_larg_dict[i]\n",
        "    \n",
        "    if coord == False:\n",
        "      return new_data[['placeName', 'placeDesc', 'placeURL', 'new_similarity']].sort_values(by=['new_similarity'], ascending=False)\n",
        "    else:\n",
        "      return new_data[['placeName', 'placeDesc', 'placeAlt', 'placeLong', 'placeURL',\n",
        "                       'placeAddress', 'numPeopleVisited', 'new_similarity']].sort_values(by=['new_similarity'], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtfLX8KkFbRi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "cae8f4bc-04de-4fce-b1a8-90da1f94d3aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    placeName  \\\n",
              "141                       Museum of the Weird   \n",
              "1205        Harvard Museum of Natural History   \n",
              "6216                          Sweet Home Cafe   \n",
              "2738                   Museum of Mourning Art   \n",
              "3410             Geppi's Entertainment Museum   \n",
              "2196                   Roanoke Pinball Museum   \n",
              "4460                  American Writers Museum   \n",
              "2665                     Milwaukee Art Museum   \n",
              "1385                 Glore Psychiatric Museum   \n",
              "360        The CDC Museum in Atlanta, Georgia   \n",
              "3171  The Renwick Gallery in Washington, D.C.   \n",
              "\n",
              "                                              placeDesc  \\\n",
              "141   The dime or dime store museum is by all accoun...   \n",
              "1205  Collecting three different institutions into o...   \n",
              "6216  Thomas Downing was the oyster king. In 19th-ce...   \n",
              "2738  Mourning and personal response to death are un...   \n",
              "3410  It’s a unique place that can create a sentimen...   \n",
              "2196  In downtown Roanoke inside the “Center in the ...   \n",
              "4460  The American Writers Museum—tucked away on the...   \n",
              "2665  Like the Guggenheim in New York and the Oaklan...   \n",
              "1385  Located in St. Joseph, Missouri, the Glore Psy...   \n",
              "360   In the 1995 hit film Outbreak, residents of th...   \n",
              "3171  The Renwick Gallery building has the distincti...   \n",
              "\n",
              "                                               placeURL new_similarity  \n",
              "141     http://www.atlasobscura.com/places/museum-weird       0.664293  \n",
              "1205  http://www.atlasobscura.com/places/harvard-mus...       0.652497  \n",
              "6216  http://www.atlasobscura.com/places/sweet-home-...       0.638549  \n",
              "2738  http://www.atlasobscura.com/places/museum-of-m...       0.589188  \n",
              "3410  http://www.atlasobscura.com/places/geppi-s-ent...       0.568464  \n",
              "2196  http://www.atlasobscura.com/places/roanoke-pin...       0.563887  \n",
              "4460  http://www.atlasobscura.com/places/american-wr...       0.561864  \n",
              "2665  http://www.atlasobscura.com/places/milwaukee-a...       0.561737  \n",
              "1385  http://www.atlasobscura.com/places/glore-psych...       0.560594  \n",
              "360       http://www.atlasobscura.com/places/cdc-museum       0.558526  \n",
              "3171  http://www.atlasobscura.com/places/renwick-gal...       0.557571  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b4866f8-9504-4b34-82f4-c051e0914d92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>placeName</th>\n",
              "      <th>placeDesc</th>\n",
              "      <th>placeURL</th>\n",
              "      <th>new_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>Museum of the Weird</td>\n",
              "      <td>The dime or dime store museum is by all accoun...</td>\n",
              "      <td>http://www.atlasobscura.com/places/museum-weird</td>\n",
              "      <td>0.664293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1205</th>\n",
              "      <td>Harvard Museum of Natural History</td>\n",
              "      <td>Collecting three different institutions into o...</td>\n",
              "      <td>http://www.atlasobscura.com/places/harvard-mus...</td>\n",
              "      <td>0.652497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6216</th>\n",
              "      <td>Sweet Home Cafe</td>\n",
              "      <td>Thomas Downing was the oyster king. In 19th-ce...</td>\n",
              "      <td>http://www.atlasobscura.com/places/sweet-home-...</td>\n",
              "      <td>0.638549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2738</th>\n",
              "      <td>Museum of Mourning Art</td>\n",
              "      <td>Mourning and personal response to death are un...</td>\n",
              "      <td>http://www.atlasobscura.com/places/museum-of-m...</td>\n",
              "      <td>0.589188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3410</th>\n",
              "      <td>Geppi's Entertainment Museum</td>\n",
              "      <td>It’s a unique place that can create a sentimen...</td>\n",
              "      <td>http://www.atlasobscura.com/places/geppi-s-ent...</td>\n",
              "      <td>0.568464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2196</th>\n",
              "      <td>Roanoke Pinball Museum</td>\n",
              "      <td>In downtown Roanoke inside the “Center in the ...</td>\n",
              "      <td>http://www.atlasobscura.com/places/roanoke-pin...</td>\n",
              "      <td>0.563887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4460</th>\n",
              "      <td>American Writers Museum</td>\n",
              "      <td>The American Writers Museum—tucked away on the...</td>\n",
              "      <td>http://www.atlasobscura.com/places/american-wr...</td>\n",
              "      <td>0.561864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2665</th>\n",
              "      <td>Milwaukee Art Museum</td>\n",
              "      <td>Like the Guggenheim in New York and the Oaklan...</td>\n",
              "      <td>http://www.atlasobscura.com/places/milwaukee-a...</td>\n",
              "      <td>0.561737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1385</th>\n",
              "      <td>Glore Psychiatric Museum</td>\n",
              "      <td>Located in St. Joseph, Missouri, the Glore Psy...</td>\n",
              "      <td>http://www.atlasobscura.com/places/glore-psych...</td>\n",
              "      <td>0.560594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>The CDC Museum in Atlanta, Georgia</td>\n",
              "      <td>In the 1995 hit film Outbreak, residents of th...</td>\n",
              "      <td>http://www.atlasobscura.com/places/cdc-museum</td>\n",
              "      <td>0.558526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3171</th>\n",
              "      <td>The Renwick Gallery in Washington, D.C.</td>\n",
              "      <td>The Renwick Gallery building has the distincti...</td>\n",
              "      <td>http://www.atlasobscura.com/places/renwick-gal...</td>\n",
              "      <td>0.557571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b4866f8-9504-4b34-82f4-c051e0914d92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b4866f8-9504-4b34-82f4-c051e0914d92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b4866f8-9504-4b34-82f4-c051e0914d92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "query = 'american museum'\n",
        "city = 'new york'\n",
        "num_docs_retrieved = 10\n",
        "search_engine_v3(query, city, data3, n=num_docs_retrieved)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiyjSOzDcV0u"
      },
      "source": [
        "The results between the second search engine and the third changes but it's difficult to say which one is better in absolute terms. In the third we are searching not specifically the most similar descriptions to the query but we are tacking into account more information, it retrieves thhe most similar places but it gives precedence to the ones nearest the city requested and the 'hottest' places of the moment, that are the ones that more people want to visit. So it will better if a user is interested in this specific result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWDnO280A_zq"
      },
      "source": [
        "## 4. Visualizing the most relevant places\n",
        "\n",
        "Using maps can help people understand how far one place is from another so they can plan their trips more adequately. Here we challenge you to show a map with the places found with the score defined in point 3. Ensure you can at least identify and visualize the _name_, _city_, _country_, _address_ and the _number of people who visited_ each place. You can find some ideas on how to create maps in Python [here](https://plotly.com/python/maps/) and [here](https://towardsdatascience.com/visualizing-geospatial-data-in-python-e070374fe621) but don't limit yourselves, let your minds fly!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbZuDd66GHwK"
      },
      "outputs": [],
      "source": [
        "data_map_plot = search_engine_v3(query, city, data3, n=num_docs_retrieved, coord=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am6aaTS-BQuN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "abefce21-9bfb-40a3-e74e-128a5cbfdef4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b99098f6-c2fa-4db6-b7ab-a590b237f210\" class=\"plotly-graph-div\" style=\"height:600px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b99098f6-c2fa-4db6-b7ab-a590b237f210\")) {                    Plotly.newPlot(                        \"b99098f6-c2fa-4db6-b7ab-a590b237f210\",                        [{\"customdata\":[[\"Museum of the Weird 412 E 6th St. Austin, Texas, 78701 United States\",1013.0],[\"26 Oxford Street Cambridge, Massachusetts, 02138 United States\",1004.0],[\"National Museum of African American History and Culture 1400 Constitution Ave NW Washington, District of Columbia United States\",191.0],[\"2900 State Road Upper Darby, Pennsylvania, 19026 United States\",53.0],[\"301 W Camden St Baltimore, Maryland, 21201 United States\",254.0],[\"One Market Square SE Roanoke Pinball Museum Roanoke, Virginia United States\",232.0],[\"180 N Michigan Ave Chicago, Illinois, 60601 United States\",180.0],[\"700 N. Art Museum Dr. Milwaukee, Wisconsin, 53202 United States\",1648.0],[\"3408 Frederick Ave St. Joseph, Missouri, 64506 United States\",383.0],[\"1600 Clifton Rd Atlanta, Georgia, 30329 United States\",450.0],[\"Washington, District of Columbia, 20506 United States\",1268.0]],\"hovertemplate\":\"<b>%{hovertext}</b><br><br>placeAlt=%{lat}<br>placeLong=%{lon}<br>placeAddress=%{customdata[0]}<br>numPeopleVisited=%{customdata[1]}<extra></extra>\",\"hovertext\":[\"Museum of the Weird\",\"Harvard Museum of Natural History\",\"Sweet Home Cafe\",\"Museum of Mourning Art\",\"Geppi's Entertainment Museum\",\"Roanoke Pinball Museum\",\"American Writers Museum\",\"Milwaukee Art Museum\",\"Glore Psychiatric Museum\",\"The CDC Museum in Atlanta, Georgia\",\"The Renwick Gallery in Washington, D.C.\"],\"lat\":[30.267022,42.378936,38.891064,39.955859,39.283594,37.271471,41.885556,43.038456,39.776906,33.798989,38.899019],\"legendgroup\":\"\",\"lon\":[-97.738744,-71.115227,-77.032614,-75.297094,-76.619681,-79.939477,-87.624881,-87.897475,-94.814689,-84.329715,-77.039063],\"marker\":{\"color\":\"blue\"},\"mode\":\"markers\",\"name\":\"\",\"showlegend\":false,\"subplot\":\"mapbox\",\"type\":\"scattermapbox\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"mapbox\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"center\":{\"lat\":38.67698836363637,\"lon\":-82.67715090909091},\"zoom\":3,\"style\":\"open-street-map\"},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":0,\"r\":0,\"l\":0,\"b\":0},\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b99098f6-c2fa-4db6-b7ab-a590b237f210');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter_mapbox(\n",
        "    data_map_plot,\n",
        "    lat = \"placeAlt\",\n",
        "    lon = \"placeLong\",\n",
        "    hover_name = \"placeName\",\n",
        "    hover_data = [\"placeAddress\", \"numPeopleVisited\"],\n",
        "    color_discrete_sequence = [\"blue\"],\n",
        "    zoom = 3,\n",
        "    height = 600)\n",
        "\n",
        "fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXIqvkv5BQ3X"
      },
      "source": [
        "## 5. BONUS: More complex search engine\n",
        "\n",
        "__IMPORTANT:__ This is a bonus step, so it's not mandatory. You can get the maximum score also without doing this. We will take this into account, only if the rest of the homework has been completed.\n",
        "\n",
        "For the Bonus part, we want to ask you more sophisticated search engine. Here we want to let users issue more complex queries. The options of this new search engine are:\n",
        "\n",
        "1. Give the possibility to specify queries for the following features (the user should have the option to issue none or all of them):\n",
        "\n",
        "- `placeName`\n",
        "- `placeDesc`\n",
        "- `placeAddress`\n",
        "\n",
        "2. Specify a list of usernames to only retrieve the posts that all of these users contributed to.\n",
        "\n",
        "3. Specify a list of tags which the search engine should only return the places that are tagged with all of those tags.\n",
        "\n",
        "4. Filter based on the number of people who have already been there. The user should be able to adjust the upperbound, lowerbound or only one of the two.\n",
        "\n",
        "5. Specify a list of the list names that the engine should only filter the documents that have been included in all of the given list names.\n",
        "\n",
        "__Note 1:__ You should be aware that you should give the user the possibility to select any of the abovementioned options. How should the user use the options? We will accept any manual that you provide to the user.\n",
        "\n",
        "__Note 2:__ As you may have realized from 1st option, you need to build inverted indexes for those values and return all of the documents that have the similarity more than 0 concerning the given queries. Choose a logical way to aggregate the similarity coming from each of them and explain your idea in detail.\n",
        "\n",
        "__Note 3:__ The options other than 1st one can be considered as filtering criteria so the retrieved documents must respect all of those filters.\n",
        "\n",
        "The output must contain the following information about the places:\n",
        "\n",
        "- `placeName`\n",
        "- `placeURL`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx4ipxG8BmKw"
      },
      "source": [
        "## 6. Command line question\n",
        "\n",
        "As done in the previous assignment, we encourage using the command as a feature that Data Scientists must master.\n",
        "\n",
        "In this question, you should use command line tools such as `grep` (or any other commands) to answer the following question:\n",
        "\n",
        "$\\bullet$ For the countries Italy, Spain, France, England, and the United States, report the following (using the information scraped in point 1.3):\n",
        "\n",
        "1. How many places can be found in each country?\n",
        "\n",
        "2. How many people, on average, have visited the places in each country?\n",
        "\n",
        "3. How many people in total want to visit the places in each country?\n",
        "\n",
        "_Note:_ You may work on this question in any environment (AWS, your PC command line, Jupyter notebook, etc.), but the final script must be placed in CommandLine.sh, which must be executable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-snD0sxB3JF"
      },
      "source": [
        "## 7. Theoretical question\n",
        "\n",
        "An imaginary university is interested in accepting some of the applicants for positions to study the Master of Data Science there. Unfortunately, only a few spots are available, so the university requires students to take some exams. Students are then admitted based on how well they perform on these exams. For students to determine whether they have been successfully accepted to the university, the university wants to create a ranking list that includes every student's first name, last name, and total average on its course webpage. Students should be ranked in the list based on their average points in descending order. For example, if two students have the same average punctuation, they should be sorted in ascending order using their first and last names. University will give you the students' information in __'ApplicantsInfo.txt'__ ([click here to download](https://adm2022.s3.amazonaws.com/ApplicantsInfo.txt)), and you should provide them with the ranking list in another .txt file and name it as __'RankingList.txt'__ . Kindly help this university in preparing this ranking list.\n",
        "\n",
        "__Input: 'ApplicantsInfo.txt'__ will have the following format:\n",
        "\n",
        "- In the first line, you will be given n as the number of applicants and m as the number of exams that students have taken (all of them have taken the same exams), where:\n",
        "\n",
        "$$ 0 < n \\leq 5*10^4 $$\n",
        "$$ 1 \\leq m \\leq 10^3 $$\n",
        "\n",
        "- In each following _n_ lines, you will find the information related to one of the students. Their first name, last name and _m_ integers as the grades they received in _m_ courses.\n",
        "\n",
        "__Output:__ The output file should consist of __n__ lines, with each line representing one of the students and including the student's __first name__, __last name__, and __total average point__ (setting the precision to 2 decimal points). As you know, they must be sorted in the order specified in the problem description.\n",
        "\n",
        "__Examples:__\n",
        "\n",
        "__Input 1__\n",
        "\n",
        "```\n",
        "10 3\n",
        "Emily Morris 27 22 27\n",
        "Maria Choute 24 18 21\n",
        "Maura Lara 27 22 18\n",
        "Daniel Falgoust 28 29 24\n",
        "Henrietta Kaul 27 29 30\n",
        "Devin Lee 23 21 27\n",
        "Anne Ortega 21 24 23\n",
        "Robert Wasserman 29 28 21\n",
        "Sue Csaszar 21 25 25\n",
        "Rebecca Lachner 23 30 30\n",
        "```\n",
        "\n",
        "__Output 1__\n",
        "\n",
        "```\n",
        "Henrietta Kaul 28.67\n",
        "Rebecca Lachner 27.67\n",
        "Daniel Falgoust 27.0\n",
        "Robert Wasserman 26.0\n",
        "Emily Morris 25.33\n",
        "Devin Lee 23.67\n",
        "Sue Csaszar 23.67\n",
        "Anne Ortega 22.67\n",
        "Maura Lara 22.33\n",
        "Maria Choute 21.0\n",
        "```\n",
        "\n",
        "__Input 2__\n",
        "\n",
        "```\n",
        "5 6\n",
        "Ralph Broadus 29 22 27 27 19 30\n",
        "Patricia Melancon 18 22 30 25 23 27\n",
        "Robert Watson 21 18 30 19 28 22\n",
        "Matthew Longsdorf 26 19 28 30 21 30\n",
        "Linda Allison 29 25 21 24 25 28\n",
        "```\n",
        "\n",
        "__Output 2__\n",
        "\n",
        "```\n",
        "Matthew Longsdorf 25.67\n",
        "Ralph Broadus 25.67\n",
        "Linda Allison 25.33\n",
        "Patricia Melancon 24.17\n",
        "Robert Watson 23.0\n",
        "```\n",
        "\n",
        "1. Try solving the problem mentioned above using three different sorting algorithms (do not use any MapReduce algorithm). (Note: Built-in Python functions (like .mean, .sort, etc.) are not allowed to be used. You must implement the algorithms from scratch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBGjAWF2GWOi"
      },
      "source": [
        "First bubble sort algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf1RS-mjCl7C"
      },
      "outputs": [],
      "source": [
        "# function to sort the lists using the second element of sublists wich are the students grade else if the students grade are equal it sort it alphabetically\n",
        "# using of third variable\n",
        "def sorting(lista):\n",
        "    for i in range(0, len(lista)):\n",
        "        for j in range(0, len(lista)-i-1):\n",
        "            # if the second element of the line j is less than the second element of next line we change the order of the lines\n",
        "            if (lista[j][1] < lista[j + 1][1]):\n",
        "                tempo = lista[j]\n",
        "                lista[j]= lista[j + 1]\n",
        "                lista[j + 1]= tempo\n",
        "            # if the second element of line j and j+1 is equal then we change the order depending of first element of the line (in our case alphabetically)\n",
        "            elif (lista[j][1] == lista[j + 1][1]):\n",
        "                if (lista[j][0] > lista[j + 1][0]):\n",
        "                    tempo = lista[j]\n",
        "                    lista[j]= lista[j + 1]\n",
        "                    lista[j + 1]= tempo\n",
        "    # return the sorted list                \n",
        "    return lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2f7AnzvGid_"
      },
      "outputs": [],
      "source": [
        "# open existed text file ApplicantsInfo and save the output in a new text file RankingList \n",
        "with open('/content/drive/MyDrive/ADM_HW_3/ApplicantsInfo.txt') as f1, open('/content/drive/MyDrive/ADM_HW_3/RankingList.txt', 'a') as f2:\n",
        "    # content of the file f1 as a list\n",
        "    f1=list(f1)\n",
        "    # empty list\n",
        "    x=[]\n",
        "    for line in f1[1:]:\n",
        "        # take combined input name and exams grades and split values using split function\n",
        "        raw = line.rstrip().split()\n",
        "        # we sum the elements of each line strating from the third element (the first and second elements are name and surname)\n",
        "        grades = sum(int(i) for i in raw[2:])\n",
        "        # average of the grades\n",
        "        average = grades/len(raw[2:])\n",
        "        # we concatenate the first two element name and surname to the third element which is the average round to two only decimals\n",
        "        new_data = ' '.join(raw[:2] + [str(\"%.2f\" % average)])\n",
        "        # we append the results in a list\n",
        "        x.append(new_data)\n",
        "    # two empty lists\n",
        "    ls1 = []\n",
        "    for i in x[:]:\n",
        "        # take combined input name and grade and split values using split function\n",
        "        x = i.rstrip().split()[0]+' '+i.rstrip().split()[1]\n",
        "        y = i.rstrip().split()[2]\n",
        "      # add name and grades in a list\n",
        "        ls1.append((x,y))\n",
        "    # sort the list and save it in the new text file \n",
        "    sorting(ls1)  \n",
        "    for i in ls1:\n",
        "        # print name and marks stored \n",
        "        print(i[0]+' '+i[1],file=f2)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGsmtW81GjPZ"
      },
      "source": [
        "Second insertion sort algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8Qyuy9OGnK2"
      },
      "outputs": [],
      "source": [
        "def sorting2(lista):\n",
        "    for i in range(1, len(lista)):\n",
        "        x = lista[i]\n",
        "        j = i - 1\n",
        "        # compare the element of the array from left until a bigger element is found (for position [1])\n",
        "        while j >= 0 and x[1] > lista[j][1]:\n",
        "            lista[j + 1] = lista[j]\n",
        "            j = j - 1\n",
        "        lista[j + 1] = x\n",
        "        # if two elements are equal (for position [1])\n",
        "        if j >= 0 and x[1] == lista[j][1]:\n",
        "            # we compare element of the array with respect to position [0]\n",
        "            if (x[0] < lista[j][0]):\n",
        "                lista[j + 1] = lista[j]\n",
        "                j = j - 1\n",
        "        # move the element x after the element which is bigger than x\n",
        "        lista[j + 1] = x\n",
        "    return lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV9-TnjKGpTC"
      },
      "outputs": [],
      "source": [
        "# open existed text file ApplicantsInfo and save the output in a new text file RankingList \n",
        "with open('/content/drive/MyDrive/ADM_HW_3/ApplicantsInfo.txt') as f1, open('/content/drive/MyDrive/ADM_HW_3/RankingList.txt', 'a') as f2:\n",
        "    # content of the file f1 as a list\n",
        "    f1=list(f1)\n",
        "    # empty list\n",
        "    x=[]\n",
        "    for line in f1[1:]:\n",
        "        # take combined input name and exams grades and split values using split function\n",
        "        raw = line.rstrip().split()\n",
        "        # we sum the elements of each line strating from the third element (the first and second elements are name and surname)\n",
        "        grades = sum(int(i) for i in raw[2:])\n",
        "        # average of the grades\n",
        "        average = grades/len(raw[2:])\n",
        "        # we concatenate the first two element name and surname to the third element which is the average round to two only decimals\n",
        "        new_data = ' '.join(raw[:2] + [str(\"%.2f\" % average)])\n",
        "        # we append the results in a list\n",
        "        x.append(new_data)\n",
        "    # two empty lists\n",
        "    ls1 = []\n",
        "    for i in x[:]:\n",
        "        # take combined input name and grade and split values using split function\n",
        "        x = i.rstrip().split()[0]+' '+i.rstrip().split()[1]\n",
        "        y = i.rstrip().split()[2]\n",
        "      # add name and grades in a list\n",
        "        ls1.append((x,y))\n",
        "    # sort the list and save it in the new text file \n",
        "    sorting2(ls1)  \n",
        "    for i in ls1:\n",
        "        # print name and marks stored \n",
        "        print(i[0]+' '+i[1],file=f2)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0x8ez2dGr-o"
      },
      "source": [
        "Third selection sort algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORGTJ-ioGw4T"
      },
      "outputs": [],
      "source": [
        "def sorting3(lista):\n",
        "    for step in range(len(lista)):\n",
        "        min_idx = step\n",
        "        for i in range(step + 1, len(lista)):\n",
        "            if lista[i][1] > lista[min_idx][1]:\n",
        "                min_idx = i\n",
        "            elif lista[i][1] == lista[min_idx][1]:\n",
        "                if lista[i][0] < lista[min_idx][0]:\n",
        "                    min_idx = i\n",
        "        # change the position of the element\n",
        "        (lista[step], lista[min_idx]) = (lista[min_idx], lista[step])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8lNbqS7G2Lr"
      },
      "outputs": [],
      "source": [
        "# open existed text file ApplicantsInfo and save the output in a new text file RankingList \n",
        "with open('/content/drive/MyDrive/ADM_HW_3/ApplicantsInfo.txt') as f1, open('/content/drive/MyDrive/ADM_HW_3/RankingList.txt', 'a') as f2:\n",
        "    # content of the file f1 as a list\n",
        "    f1=list(f1)\n",
        "    # empty list\n",
        "    x=[]\n",
        "    for line in f1[1:]:\n",
        "        # take combined input name and exams grades and split values using split function\n",
        "        raw = line.rstrip().split()\n",
        "        # we sum the elements of each line strating from the third element (the first and second elements are name and surname)\n",
        "        grades = sum(int(i) for i in raw[2:])\n",
        "        # average of the grades\n",
        "        average = grades/len(raw[2:])\n",
        "        # we concatenate the first two element name and surname to the third element which is the average round to two only decimals\n",
        "        new_data = ' '.join(raw[:2] + [str(\"%.2f\" % average)])\n",
        "        # we append the results in a list\n",
        "        x.append(new_data)\n",
        "    # two empty lists\n",
        "    ls1 = []\n",
        "    for i in x[:]:\n",
        "        # take combined input name and grade and split values using split function\n",
        "        x = i.rstrip().split()[0]+' '+i.rstrip().split()[1]\n",
        "        y = i.rstrip().split()[2]\n",
        "      # add name and grades in a list\n",
        "        ls1.append((x,y))\n",
        "    # sort the list and save it in the new text file \n",
        "    sorting3(ls1)  \n",
        "    for i in ls1:\n",
        "        # print name and marks stored \n",
        "        print(i[0]+' '+i[1],file=f2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTk5ciQkHN-C"
      },
      "source": [
        "2. What is the time complexity of each algorithm you have used?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ0jeI4GHC6M"
      },
      "source": [
        "The time complexity of the first algorithm is O(n^2)\\\n",
        "The time complexity of the second algorithm is O(n^2)\\\n",
        "The time complexity of the third algorithm is O(n^2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhnDNI3eHcfg"
      },
      "source": [
        "3. Evaluate the time taken for each of your implementations to answer the query stored in the __ApplicantsInfo.txt__ file and visualize them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxbDoRgfIJ4x"
      },
      "source": [
        "Time taken by the first algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfhXurbfIDtU",
        "outputId": "57ec7401-4e50-4bd0-9175-d683a8ae9cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time required to run the first algorithm is  0:10:40.130661\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import timedelta\n",
        "start_time = time.monotonic()\n",
        "# open existed text file ApplicantsInfo and save the output in a new text file RankingList \n",
        "with open('/content/drive/MyDrive/ADM_HW_3/ApplicantsInfo.txt') as f1, open('/content/drive/MyDrive/ADM_HW_3/RankingList1.txt', 'a') as f2:\n",
        "    # content of the file f1 as a list\n",
        "    f1=list(f1)\n",
        "    # empty list\n",
        "    x=[]\n",
        "    for line in f1[1:]:\n",
        "        # take combined input name and exams grades and split values using split function\n",
        "        raw = line.rstrip().split()\n",
        "        # we sum the elements of each line strating from the third element (the first and second elements are name and surname)\n",
        "        grades = sum(int(i) for i in raw[2:])\n",
        "        # average of the grades\n",
        "        average = grades/len(raw[2:])\n",
        "        # we concatenate the first two element name and surname to the third element which is the average round to two only decimals\n",
        "        new_data = ' '.join(raw[:2] + [str(\"%.2f\" % average)])\n",
        "        # we append the results in a list\n",
        "        x.append(new_data)\n",
        "    # two empty lists\n",
        "    ls1 = []\n",
        "    for i in x[:]:\n",
        "        # take combined input name and grade and split values using split function\n",
        "        x = i.rstrip().split()[0]+' '+i.rstrip().split()[1]\n",
        "        y = i.rstrip().split()[2]\n",
        "      # add name and grades in a list\n",
        "        ls1.append((x,y))\n",
        "    # sort the list and save it in the new text file \n",
        "    sorting(ls1)  \n",
        "    for i in ls1:\n",
        "        # print name and marks stored \n",
        "        print(i[0]+' '+i[1],file=f2)\n",
        "\n",
        "a = open('/content/drive/MyDrive/ADM_HW_3/RankingList1.txt','r')   \n",
        "#print( list(a) )\n",
        "\n",
        "end_time = time.monotonic()\n",
        "time1=(end_time - start_time)\n",
        "print('The time required to run the first algorithm is ',timedelta(seconds=end_time - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6XWpGiQIQqB"
      },
      "source": [
        " Time taken by the second algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x-NHT9JISQa",
        "outputId": "d99f5a9b-f355-4f93-9eab-652e544c516e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time required to run the first algorithm is  0:03:32.695504\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import timedelta\n",
        "start_time = time.monotonic()\n",
        "# open existed text file ApplicantsInfo and save the output in a new text file RankingList \n",
        "with open('/content/drive/MyDrive/ADM_HW_3/ApplicantsInfo.txt') as f1, open('/content/drive/MyDrive/ADM_HW_3/RankingList2.txt', 'a') as f2:\n",
        "    # content of the file f1 as a list\n",
        "    f1=list(f1)\n",
        "    # empty list\n",
        "    x=[]\n",
        "    for line in f1[1:]:\n",
        "        # take combined input name and exams grades and split values using split function\n",
        "        raw = line.rstrip().split()\n",
        "        # we sum the elements of each line strating from the third element (the first and second elements are name and surname)\n",
        "        grades = sum(int(i) for i in raw[2:])\n",
        "        # average of the grades\n",
        "        average = grades/len(raw[2:])\n",
        "        # we concatenate the first two element name and surname to the third element which is the average round to two only decimals\n",
        "        new_data = ' '.join(raw[:2] + [str(\"%.2f\" % average)])\n",
        "        # we append the results in a list\n",
        "        x.append(new_data)\n",
        "    # two empty lists\n",
        "    ls1 = []\n",
        "    for i in x[:]:\n",
        "        # take combined input name and grade and split values using split function\n",
        "        x = i.rstrip().split()[0]+' '+i.rstrip().split()[1]\n",
        "        y = i.rstrip().split()[2]\n",
        "      # add name and grades in a list\n",
        "        ls1.append((x,y))\n",
        "    # sort the list and save it in the new text file \n",
        "    sorting2(ls1)  \n",
        "    for i in ls1:\n",
        "        # print name and marks stored \n",
        "        print(i[0]+' '+i[1],file=f2)\n",
        "\n",
        "a = open('/content/drive/MyDrive/ADM_HW_3/RankingList2.txt','r')   \n",
        "#print( list(a) )\n",
        "\n",
        "end_time = time.monotonic()\n",
        "time2=(end_time - start_time)\n",
        "print('The time required to run the first algorithm is ',timedelta(seconds=end_time - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRvdAbfzIWHX"
      },
      "source": [
        "Time taken by the third algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66wHCp9sIWUg",
        "outputId": "cf7ee90f-1b17-423d-b36e-b07cf2757143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time required to run the first algorithm is  0:06:55.103977\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import timedelta\n",
        "start_time = time.monotonic()\n",
        "# open existed text file ApplicantsInfo and save the output in a new text file RankingList \n",
        "with open('/content/drive/MyDrive/ADM_HW_3/ApplicantsInfo.txt') as f1, open('/content/drive/MyDrive/ADM_HW_3/RankingList3.txt', 'a') as f2:\n",
        "    # content of the file f1 as a list\n",
        "    f1=list(f1)\n",
        "    # empty list\n",
        "    x=[]\n",
        "    for line in f1[1:]:\n",
        "        # take combined input name and exams grades and split values using split function\n",
        "        raw = line.rstrip().split()\n",
        "        # we sum the elements of each line strating from the third element (the first and second elements are name and surname)\n",
        "        grades = sum(int(i) for i in raw[2:])\n",
        "        # average of the grades\n",
        "        average = grades/len(raw[2:])\n",
        "        # we concatenate the first two element name and surname to the third element which is the average round to two only decimals\n",
        "        new_data = ' '.join(raw[:2] + [str(\"%.2f\" % average)])\n",
        "        # we append the results in a list\n",
        "        x.append(new_data)\n",
        "    # two empty lists\n",
        "    ls1 = []\n",
        "    for i in x[:]:\n",
        "        # take combined input name and grade and split values using split function\n",
        "        x = i.rstrip().split()[0]+' '+i.rstrip().split()[1]\n",
        "        y = i.rstrip().split()[2]\n",
        "      # add name and grades in a list\n",
        "        ls1.append((x,y))\n",
        "    # sort the list and save it in the new text file \n",
        "    sorting3(ls1)  \n",
        "    for i in ls1:\n",
        "        # print name and marks stored \n",
        "        print(i[0]+' '+i[1],file=f2)\n",
        "\n",
        "a = open('/content/drive/MyDrive/ADM_HW_3/RankingList3.txt','r')   \n",
        "#print( list(a) )\n",
        "\n",
        "end_time = time.monotonic()\n",
        "time3=(end_time - start_time)\n",
        "print('The time required to run the first algorithm is ',timedelta(seconds=end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "gpYt9O7O-lHw",
        "outputId": "2cffe883-17c7-4adf-b518-302f684887a8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "time_list = [time1, time2, time3]\n",
        "x = np.arange(len(time_list))\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "plt.bar(x, time_list,color = 'firebrick')\n",
        "plt.xticks(x, ('Bubble sort','Insertion sort', 'Selection sort'))\n",
        "plt.title(\"the time requiered to run the algorithm\")\n",
        "ax.set_xlabel(\"The sort Algorithms\")\n",
        "ax.set_ylabel(\"Time\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zja5KjcgHe2k"
      },
      "source": [
        "4. What is the most optimal algorithm, in your opinion, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tvAkQQXIivk"
      },
      "source": [
        "The second algorithm is the optimal algorithm as these algorithm uses less time with respect to the other algorithms as we can see from the last question, and also guarantee the same results of the other algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xubH_kaQHT6-"
      },
      "source": [
        "5. Implement a sorting algorithm using MapReduce and compare it against the three algorithms previously implemented using the __ApplicantsInfo.txt__ file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UasSpycIqYj"
      },
      "outputs": [],
      "source": [
        "def sorting4(lista):\n",
        "    if len(lista) > 1:\n",
        "        i = j = k = 0\n",
        "        #  first we divided the array into two subarrays\n",
        "        middle = len(lista)//2\n",
        "        # the first array from start to middle \n",
        "        F = lista[:middle]\n",
        "        # the second array from middle to end \n",
        "        S = lista[middle:]\n",
        "        # sorting function for the first part of the array\n",
        "        sorting4(F)\n",
        "        # sorting function for the second part of the array\n",
        "        sorting4(S)\n",
        "        # sort the elements of the arrays by grades then alphabetically \n",
        "        while i < len(F) and j < len(S):\n",
        "            if F[i][1] > S[j][1]:\n",
        "                lista[k] = F[i]\n",
        "                i += 1\n",
        "            elif F[i][1] == S[j][1] and F[i][0] < S[j][0]:\n",
        "                lista[k] = F[i]\n",
        "                i += 1\n",
        "            else:\n",
        "                lista[k] = S[j]\n",
        "                j += 1\n",
        "            k += 1\n",
        "        # put the remaining elements in the array\n",
        "        while i < len(F):\n",
        "            lista[k] = F[i]\n",
        "            i += 1\n",
        "            k += 1\n",
        "        while j < len(S):\n",
        "            lista[k] = S[j]\n",
        "            j += 1\n",
        "            k += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5e_-BUkIwrh",
        "outputId": "b59cbc76-3941-4a9a-a876-b30fbdb1e66d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time required to run the third algorithm is  0:00:14.199889\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import timedelta\n",
        "start_time = time.monotonic()\n",
        "# open existed text file ApplicantsInfo and save the output in a new text file RankingList \n",
        "with open('/content/drive/MyDrive/ADM_HW_3/ApplicantsInfo.txt') as f1, open('/content/drive/MyDrive/ADM_HW_3/RankingList4.txt', 'a') as f2:\n",
        "    # content of the file f1 as a list\n",
        "    f1=list(f1)\n",
        "    # empty list\n",
        "    x=[]\n",
        "    for line in f1[1:]:\n",
        "        # take combined input name and exams grades and split values using split function\n",
        "        raw = line.rstrip().split()\n",
        "        # we sum the elements of each line strating from the third element (the first and second elements are name and surname)\n",
        "        grades = sum(int(i) for i in raw[2:])\n",
        "        # average of the grades\n",
        "        average = grades/len(raw[2:])\n",
        "        # we concatenate the first two element name and surname to the third element which is the average round to two only decimals\n",
        "        new_data = ' '.join(raw[:2] + [str(\"%.2f\" % average)])\n",
        "        # we append the results in a list\n",
        "        x.append(new_data)\n",
        "    # two empty lists\n",
        "    ls1 = []\n",
        "    for i in x[:]:\n",
        "        # take combined input name and grade and split values using split function\n",
        "        x = i.rstrip().split()[0]+' '+i.rstrip().split()[1]\n",
        "        y = i.rstrip().split()[2]\n",
        "      # add name and grades in a list\n",
        "        ls1.append((x,y))\n",
        "    # sort the list and save it in the new text file \n",
        "    sorting4(ls1)  \n",
        "    for i in ls1:\n",
        "        # print name and marks stored \n",
        "        print(i[0]+' '+i[1],file=f2)\n",
        "\n",
        "a = open('/content/drive/MyDrive/ADM_HW_3/RankingList4.txt','r')   \n",
        "#print( list(a) )\n",
        "\n",
        "end_time = time.monotonic()\n",
        "print('The time required to run the third algorithm is ',timedelta(seconds=end_time - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXNfZ_LuIiJT"
      },
      "source": [
        "The mapreduce algorithm has time complexity of O(nlogn), which is a significant improvement over the other algorithms. The mapreduce algorithm is fast with respect to the others as we can see it requieres only 14 seconds, while the fastest algorithm among the three first algorithms which is insertion sort algorithm requieres 3 minutes and 32 seconds to execute the code."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dx4ipxG8BmKw"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}